<<<<<<< HEAD
# Gap Analysis Project - Complete Technical Documentation

## Project Overview

This project performs comprehensive **Supply-Demand Gap Analysis** for a rental business platform. It identifies product categories with supply shortages, analyzes demand patterns, and generates actionable insights for business optimization through an automated pipeline of notebooks and reusable Python modules.

---

## Project Structure

```
rently_2026/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ Project Data.xlsx                    # Raw input (8 sheets)
â”‚       â”œâ”€â”€ Cleaned_data.xlsx                    # After cleaning
â”‚       â””â”€â”€ Category_Supply_Demand_Analysis.xlsx # Supply-demand metrics
â”œâ”€â”€ Gap_Analysis/
â”‚   â”œâ”€â”€ notebooks/                               # Analysis pipeline (execute in order)
â”‚   â”‚   â”œâ”€â”€ DataUnderstandingAndExploration.ipynb
â”‚   â”‚   â”œâ”€â”€ DataCleaningAndMerging.ipynb
â”‚   â”‚   â”œâ”€â”€ ComputeCategoryLevelSupply&Demand.ipynb
â”‚   â”‚   â”œâ”€â”€ MOAZ_Define_Metrics_GapScore.ipynb
â”‚   â”‚   â”œâ”€â”€ GapScoreImplementation.ipynb
â”‚   â”‚   â”œâ”€â”€ VisualizationDraft.ipynb
â”‚   â”‚   â”œâ”€â”€ InterpretationAndInsights.ipynb
â”‚   â”‚   â””â”€â”€ Monitoring_and_Action_Plan.ipynb
â”‚   â”œâ”€â”€ src/                                     # Reusable Python modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”‚   â”œâ”€â”€ data_quality.py
â”‚   â”‚   â”œâ”€â”€ data_statistics.py
â”‚   â”‚   â”œâ”€â”€ data_preview.py
â”‚   â”‚   â”œâ”€â”€ data_relationships.py
â”‚   â”‚   â”œâ”€â”€ data_db_model.py
â”‚   â”‚   â”œâ”€â”€ data_exporter.py
â”‚   â”‚   â”œâ”€â”€ supply_demand.py
â”‚   â”‚   â”œâ”€â”€ gap_score.py
â”‚   â”‚   â”œâ”€â”€ gap_visualizer.py
â”‚   â”‚   â”œâ”€â”€ gap_dashboard_builder.py
â”‚   â”‚   â”œâ”€â”€ plotly_interactive_charts.py
â”‚   â”‚   â”œâ”€â”€ plotly_gap_charts.py
â”‚   â”‚   â”œâ”€â”€ plotly_dashboard.py
â”‚   â”‚   â”œâ”€â”€ dashboard_builder.py
â”‚   â”‚   â”œâ”€â”€ chart_insights.py
â”‚   â”‚   â”œâ”€â”€ monitoring_engine.py
â”‚   â”‚   â”œâ”€â”€ monitoring_visualizations.py
â”‚   â”‚   â””â”€â”€ action_planner.py
â”‚   â”œâ”€â”€ results/                                 # All outputs
â”‚   â”‚   â”œâ”€â”€ charts/                              # Static PNG images
â”‚   â”‚   â”œâ”€â”€ reports/                             # Excel reports
â”‚   â”‚   â”œâ”€â”€ visualizations_subcategory/          # Interactive HTML + data
â”‚   â”‚   â”œâ”€â”€ insights/                            # Text insights
â”‚   â”‚   â”œâ”€â”€ monitoring_reports/                  # Weekly snapshots
â”‚   â”‚   â””â”€â”€ monitoring_dashboards/               # Monitoring HTML
â”‚   â””â”€â”€ scripts/
â”‚       â””â”€â”€ install_requirements.sh
â””â”€â”€ README.md
```

---

## Complete Data Pipeline Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PHASE 1: DATA PREPARATION                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â†“
    [1. DataUnderstandingAndExploration.ipynb]
         INPUT: Project Data.xlsx (8 sheets)
         USES: data_loader.py, data_quality.py, data_relationships.py
         OUTPUTS:
           â€¢ Data structure analysis (console output)
           â€¢ Missing value visualizations (PNG heatmaps)
           â€¢ Database relationship diagram (output.dbml + PNG)
           â€¢ Statistical summaries (console)
         API USAGE: Not directly - exploratory only
                                      â†“
    [2. DataCleaningAndMerging.ipynb]
         INPUT: Project Data.xlsx
         USES: data_loader.py, data_quality.py, gender_guesser library
         PROCESSES:
           â€¢ Fill missing ProductColor â†’ "Mixed"
           â€¢ Fill missing ProductStyle â†’ "U" (Unisex)
           â€¢ Infer Gender from FirstName
           â€¢ Generate Prefix based on Gender + MaritalStatus
           â€¢ Convert date columns to datetime
         OUTPUTS:
           â€¢ Cleaned_data.xlsx (8 sheets, all clean)
         API USAGE: This is the master cleaned dataset
                                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   PHASE 2: SUPPLY-DEMAND COMPUTATION                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â†“
    [3. ComputeCategoryLevelSupply&Demand.ipynb]
         INPUT: Cleaned_data.xlsx
         USES: supply_demand.py, pandas, matplotlib, seaborn
         PROCESSES:
           â€¢ Merge products with categories
           â€¢ Compute category-level sales (demand)
           â€¢ Compute category-level returns (supply adjustment)
           â€¢ Calculate net demand = sales - returns
           â€¢ Generate monthly trends
         OUTPUTS:
           â€¢ Category_Supply_Demand_Analysis.xlsx
             - Sheet 1: Category Summary (4 categories)
             - Sheet 2: Monthly Trends (time series)
           â€¢ Visualizations (PNG): pie charts, bar charts, dashboards
         API USAGE: 
           - /api/categories â†’ Category Summary sheet
           - /api/trends â†’ Monthly Trends sheet
                                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PHASE 3: GAP SCORE CALCULATION                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â†“
    [4. MOAZ_Define_Metrics_GapScore.ipynb]
         INPUT: Cleaned_data.xlsx
         USES: config.py (TARGET_MULTIPLIERS), gap_analysis.py
         PROCESSES:
           â€¢ Define business KPIs (revenue, orders, customers)
           â€¢ Calculate target values using multipliers
           â€¢ Compute gap percentages
           â€¢ Classify gaps: Excellent/Good/Moderate/Severe
         OUTPUTS:
           â€¢ Console output with classified metrics
           â€¢ Bar charts showing gap levels
         API USAGE: Not directly - defines methodology only
                                      â†“
    [5. GapScoreImplementation.ipynb]
         INPUT: Cleaned_data.xlsx
         USES: supply_demand.py, gap_score.py, gap_visualizer.py
         PROCESSES:
           â€¢ Compute supply metrics (unique products per category/subcategory)
           â€¢ Compute demand metrics (orders, quantity sold)
           â€¢ Calculate Gap Score = (demand + 1) / (supply + 1)
           â€¢ Normalize and classify gap levels (Low/Moderate/High/Critical)
           â€¢ Perform subcategory-level analysis (37 subcategories)
           â€¢ Perform territory-level analysis (by region/country)
         OUTPUTS:
           â€¢ comprehensive_gap_analysis.xlsx (4 sheets):
             - Category Gaps (4 main categories)
             - Subcategory Gaps (37 subcategories)
             - Territory Gaps (category Ã— territory)
             - Detailed Gaps (subcategory Ã— territory)
           â€¢ charts/ folder: gap_score_bar.png, supply_vs_demand.png, etc.
         API USAGE: PRIMARY DATA SOURCE
           - /api/gaps/categories â†’ Category Gaps sheet
           - /api/gaps/subcategories â†’ Subcategory Gaps sheet
           - /api/gaps/territories â†’ Territory Gaps sheet
           - /api/gaps/detailed â†’ Detailed Gaps sheet
                                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PHASE 4: VISUALIZATION & INSIGHTS                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â†“
    [6. VisualizationDraft.ipynb]
         INPUT: Cleaned_data.xlsx
         USES: plotly_interactive_charts.py, dashboard_builder.py, 
               data_exporter.py, chart_insights.py
         PROCESSES:
           â€¢ Load and compute subcategory-level gaps
           â€¢ Create 5 interactive Plotly charts:
             1. Supply vs Demand comparison (dual y-axes)
             2. Gap severity analysis (color-coded bars)
             3. Normalized metrics heatmap (0-1 scale)
             4. Category rankings (top/bottom)
             5. Gap distribution pie chart
           â€¢ Generate KPI cards (avg gap, critical count, total categories)
           â€¢ Export data summaries (CSV + JSON)
         OUTPUTS:
           â€¢ results/visualizations_subcategory/
             - data/
               â€¢ subcategory_gap_summary.csv
               â€¢ subcategory_gap_summary.json
             - interactive/ (HTML files for web embedding)
               â€¢ 01_supply_vs_demand_subcategory.html
               â€¢ 02_gap_severity_subcategory.html
               â€¢ 03_gap_heatmap_subcategory.html
               â€¢ 04_subcategory_rankings.html
               â€¢ 05_gap_distribution_subcategory.html
             - images/ (PNG for reports)
               â€¢ 01_supply_vs_demand_subcategory.png
               â€¢ 02_gap_severity_subcategory.png
               â€¢ 03_gap_heatmap_subcategory.png
               â€¢ 04_subcategory_rankings.png
               â€¢ 05_gap_distribution_subcategory.png
             - insights_subcategory.txt
         API USAGE:
           - /api/visualizations/supply-demand â†’ HTML file
           - /api/visualizations/severity â†’ HTML file
           - /api/visualizations/heatmap â†’ HTML file
           - /api/data/subcategory-summary â†’ CSV/JSON
           - /api/insights/charts â†’ insights_subcategory.txt
                                      â†“
    [7. InterpretationAndInsights.ipynb]
         INPUT: Cleaned_data.xlsx
         USES: chart_insights.py (generate_interpretation_and_insights)
         PROCESSES:
           â€¢ Compute subcategory gaps
           â€¢ Generate comprehensive business insights:
             - Executive summary
             - Top gaps analysis
             - User behavior insights
             - Gap severity breakdown
             - Business recommendations
             - Next steps
         OUTPUTS:
           â€¢ results/insights/interpretation_and_insights.txt
             (2000+ word comprehensive analysis)
         API USAGE:
           - /api/insights/interpretation â†’ Full text analysis
           - /api/insights/recommendations â†’ Extracted recommendations
                                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PHASE 5: MONITORING & ACTION PLANNING                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â†“
    [8. Monitoring_and_Action_Plan.ipynb]
         INPUT: Cleaned_data.xlsx
         USES: monitoring_engine.py, action_planner.py, 
               monitoring_visualizations.py
         PROCESSES:
           â€¢ Compute current week gap scores
           â€¢ Save weekly snapshot (JSON + CSV)
           â€¢ Compare with previous week (if exists)
           â€¢ Identify categories needing attention
           â€¢ Calculate priority (High/Medium/Low)
           â€¢ Generate action plans:
             - Operational actions (immediate)
             - Strategic actions (medium-term)
             - Platform optimization
             - User engagement initiatives
           â€¢ Create monitoring visualizations
         OUTPUTS:
           â€¢ results/monitoring_reports/
             - snapshot_week_X_YYYY-MM-DD.json
             - snapshot_week_X_YYYY-MM-DD.csv
             - action_plan_week_X.json (structured data)
             - action_plan_week_X.txt (human-readable)
           â€¢ results/monitoring_dashboards/
             - 01_monitoring_kpis.html
             - 02_active_alerts.html
             - 03_supply_demand_balance.html
         API USAGE:
           - /api/monitoring/snapshot/latest â†’ Latest snapshot JSON
           - /api/monitoring/kpis â†’ KPI summary
           - /api/monitoring/alerts â†’ Flagged categories
           - /api/actions/current-week â†’ Action plan JSON
           - /api/actions/priorities â†’ Priority-sorted actions
```

---

## Python Modules Reference

### Core Data Processing Modules

#### **config.py**
- **Purpose**: Central configuration (paths, constants)
- **Key Contents**:
  - `PROJECT_ROOT`, `DATA_DIR`, `RESULTS_DIR`
  - `TARGET_MULTIPLIERS` (for KPI gap calculation)
- **Used By**: All notebooks

#### **data_loader.py**
- **Purpose**: Load Excel files into DataFrames
- **Functions**:
  - `load_excel_sheets(file_path)` â†’ dict of DataFrames
  - `summarize_excel_sheets(datasets)` â†’ summary DataFrame
- **Used By**: Notebooks 1, 2, 4

#### **data_quality.py**
- **Purpose**: Missing value analysis
- **Functions**:
  - `print_missing_data(datasets)` â†’ console output
  - `plot_missing_heatmaps(datasets)` â†’ PNG heatmaps
  - `plot_missing_summary_bar(datasets)` â†’ bar chart
- **Used By**: Notebooks 1, 2

#### **data_statistics.py**
- **Purpose**: Statistical analysis
- **Functions**:
  - `analyze_numerical_statistics(datasets)` â†’ describe()
  - `analyze_categorical_distributions(datasets)` â†’ value_counts()
- **Used By**: Notebook 1

#### **data_relationships.py**
- **Purpose**: Infer table relationships
- **Functions**:
  - `explore_structure(datasets)` â†’ column analysis
  - `infer_relationships(datasets)` â†’ foreign keys
- **Used By**: Notebook 1

#### **data_db_model.py**
- **Purpose**: Generate database diagrams
- **Functions**:
  - `generate_dbml(datasets, parent_mapping)` â†’ output.dbml file
- **Used By**: Notebook 1

---

### Supply-Demand Computation Modules

#### **supply_demand.py**
- **Purpose**: Calculate supply and demand metrics
- **Functions**:
  - `compute_category_supply(sales, products)` â†’ unique products per category
  - `compute_category_demand(sales)` â†’ orders per category
  - `compute_subcategory_supply(sales, products)` â†’ 37 subcategories
  - `compute_subcategory_demand(sales)` â†’ subcategory orders
  - `compute_territory_demand(sales, territories)` â†’ geographic analysis
  - `merge_supply_demand(supply, demand)` â†’ unified DataFrame
- **Used By**: Notebooks 3, 5, 6, 7, 8
- **API Impact**: Core metric calculation

---

### Gap Score Calculation Modules

#### **gap_score.py**
- **Purpose**: Compute and classify gap scores
- **Functions**:
  - `compute_gap_score(df, demand_col, supply_col)` â†’ gap_score = (demand+1)/(supply+1)
  - `normalize_gap_score(df)` â†’ 0-1 scale
  - `classify_gap_level(df)` â†’ Low/Moderate/High/Critical
  - `compute_demand_supply_ratio(df)` â†’ supplementary metrics
  - `rank_categories_by_gap(df)` â†’ sorted by severity
- **Used By**: Notebooks 5, 6, 7, 8
- **API Impact**: Primary gap calculation logic

---

### Visualization Modules

#### **gap_visualizer.py** (Matplotlib/Seaborn)
- **Purpose**: Static chart generation
- **Functions**:
  - `plot_gap_score_bar(df)` â†’ horizontal bar chart
  - `plot_supply_vs_demand(df)` â†’ grouped bar chart
  - `plot_gap_dashboard(df)` â†’ comprehensive dashboard
  - `plot_subcategory_gap_heatmap(df)` â†’ category Ã— subcategory
  - `plot_territory_gap_analysis(df)` â†’ geographic gaps
- **Used By**: Notebook 5
- **Output**: PNG files in results/charts/

#### **plotly_interactive_charts.py**
- **Purpose**: Interactive Plotly visualizations
- **Functions**:
  - `create_supply_demand_chart(df)` â†’ dual y-axis bar chart
  - `create_gap_score_severity_chart(df)` â†’ color-coded severity
  - `create_gap_heatmap(df)` â†’ normalized metrics heatmap
  - `create_category_ranking_chart(df)` â†’ top/bottom rankings
  - `create_gap_distribution_pie(df)` â†’ severity distribution
- **Used By**: Notebook 6
- **Output**: HTML files (embeddable in web apps)

#### **plotly_gap_charts.py**
- **Purpose**: Additional Plotly chart types
- **Functions**: Similar to plotly_interactive_charts but with different styling
- **Used By**: Notebook 6

#### **plotly_dashboard.py**
- **Purpose**: KPI card components
- **Functions**:
  - `create_kpi_card(title, value)` â†’ single metric card
  - `create_dashboard_kpi_section(kpis)` â†’ 4-card layout
  - `export_chart_png(fig, filepath)` â†’ PNG export
  - `export_chart_html(fig, filepath)` â†’ HTML export
- **Used By**: Notebooks 6, 8

#### **dashboard_builder.py**
- **Purpose**: Comprehensive dashboard assembly
- **Functions**:
  - `calculate_kpis(df)` â†’ KPI dictionary
  - `create_kpi_cards(kpis)` â†’ Plotly indicator figures
  - `create_comprehensive_dashboard(...)` â†’ multi-chart layout
- **Used By**: Notebook 6

#### **monitoring_visualizations.py**
- **Purpose**: Monitoring-specific charts
- **Functions**:
  - `create_monitoring_kpi_cards(kpis)` â†’ gauge + indicators
  - `create_gap_trend_chart(historical_df)` â†’ time series
  - `create_alert_table(flagged_df)` â†’ priority table
  - `create_change_heatmap(historical_df)` â†’ weekly changes
  - `create_supply_demand_balance_chart(df)` â†’ grouped bars
- **Used By**: Notebook 8
- **Output**: HTML dashboards

---

### Insights & Analysis Modules

#### **chart_insights.py**
- **Purpose**: Generate textual insights from data
- **Functions**:
  - `generate_supply_demand_insight(df)` â†’ single-line summary
  - `generate_severity_insight(df)` â†’ critical gap summary
  - `generate_heatmap_insight(df)` â†’ balanced categories
  - `generate_ranking_insight(df)` â†’ top gap range
  - `generate_executive_summary(df)` â†’ comprehensive dict
  - `generate_interpretation_and_insights(df)` â†’ 2000+ word analysis
- **Used By**: Notebooks 6, 7
- **API Impact**: Text content for /api/insights/*

---

### Monitoring & Action Planning Modules

#### **monitoring_engine.py**
- **Purpose**: Weekly snapshot and change tracking
- **Classes**:
  - `MonitoringSnapshot`: Save/load weekly snapshots
    - `save_snapshot(gap_df, week_number)` â†’ JSON + CSV
    - `load_latest_snapshot()` â†’ DataFrame
  - `GapChangeAnalyzer`: Compare snapshots
    - `compute_gap_change(current, previous)` â†’ change percentages
    - `identify_categories_needing_attention(df)` â†’ flagged categories
- **Functions**:
  - `compute_kpis(gap_df)` â†’ KPI dictionary
- **Used By**: Notebook 8
- **API Impact**: 
  - /api/monitoring/snapshot/* â†’ Snapshot files
  - /api/monitoring/kpis â†’ KPI data

#### **action_planner.py**
- **Purpose**: Generate actionable recommendations
- **Class**: `ActionPlanner`
  - `generate_operational_actions(category, gap_score)` â†’ immediate actions
  - `generate_strategic_actions(category, gap_score)` â†’ medium-term
  - `generate_platform_actions(category, gap_score)` â†’ tech optimizations
  - `generate_user_engagement_actions(category, gap_score)` â†’ engagement
  - `generate_category_action_plan(gap_df, week)` â†’ complete plan dict
  - `export_action_plan_json(plan, week)` â†’ JSON file
  - `export_action_plan_text(plan, week)` â†’ TXT file
- **Used By**: Notebook 8
- **API Impact**:
  - /api/actions/current-week â†’ JSON action plan
  - /api/actions/category/{name} â†’ Category-specific actions

---

### Export & Utility Modules

#### **data_exporter.py**
- **Purpose**: Standardized export functions
- **Functions**:
  - `export_dataframe_to_files(df, dir, filename)` â†’ CSV + JSON
  - `export_plotly_chart(fig, filepath, format)` â†’ HTML or PNG
  - `export_insights_to_text(insights_dict, filepath)` â†’ formatted TXT
- **Used By**: Notebooks 6, 7, 8

#### **gap_dashboard_builder.py**
- **Purpose**: Dashboard data preparation
- **Functions**:
  - `prepare_gap_summary(gap_df)` â†’ clean summary DataFrame
  - `export_gap_summary(summary, output_dir)` â†’ CSV + JSON
  - `get_kpi_metrics(summary)` â†’ KPI dictionary
- **Used By**: Notebook 6

---

## Output Files for API Integration

### Primary Data Files (Query These)

```
results/reports/
â””â”€â”€ comprehensive_gap_analysis.xlsx
    â”œâ”€â”€ Category Gaps        â†’ /api/gaps/categories
    â”œâ”€â”€ Subcategory Gaps     â†’ /api/gaps/subcategories
    â”œâ”€â”€ Territory Gaps       â†’ /api/gaps/territories
    â””â”€â”€ Detailed Gaps        â†’ /api/gaps/detailed

results/visualizations_subcategory/data/
â”œâ”€â”€ subcategory_gap_summary.csv   â†’ /api/data/subcategory-summary
â””â”€â”€ subcategory_gap_summary.json  â†’ /api/data/subcategory-summary

results/monitoring_reports/
â”œâ”€â”€ snapshot_week_X_YYYY-MM-DD.json â†’ /api/monitoring/snapshot/latest
â”œâ”€â”€ action_plan_week_X.json         â†’ /api/actions/current-week
â””â”€â”€ action_plan_week_X.txt          â†’ /api/actions/readable
```

### Visualization Files (Serve Directly)

```
results/visualizations_subcategory/interactive/
â”œâ”€â”€ 01_supply_vs_demand_subcategory.html  â†’ /api/viz/supply-demand
â”œâ”€â”€ 02_gap_severity_subcategory.html      â†’ /api/viz/severity
â”œâ”€â”€ 03_gap_heatmap_subcategory.html       â†’ /api/viz/heatmap
â”œâ”€â”€ 04_subcategory_rankings.html          â†’ /api/viz/rankings
â””â”€â”€ 05_gap_distribution_subcategory.html  â†’ /api/viz/distribution

results/monitoring_dashboards/
â”œâ”€â”€ 01_monitoring_kpis.html               â†’ /api/monitoring/kpis-dashboard
â”œâ”€â”€ 02_active_alerts.html                 â†’ /api/monitoring/alerts-dashboard
â””â”€â”€ 03_supply_demand_balance.html         â†’ /api/monitoring/balance-dashboard
```

### Insight Files (Text Content)

```
results/insights/
â””â”€â”€ interpretation_and_insights.txt  â†’ /api/insights/interpretation

results/visualizations_subcategory/
â””â”€â”€ insights_subcategory.txt         â†’ /api/insights/charts
```

---

## Key Metrics Explained

### Gap Score Formula
```
Gap Score = (Total Demand + 1) / (Total Supply + 1)
```
- **Supply** = Number of unique product listings in category
- **Demand** = Total order quantity (or number of orders)
- **+1 adjustment** = Prevents division by zero
- **Higher score** = Greater supply shortage

### Gap Classification
- **Low Gap** (< 50): Balanced supply-demand
- **Moderate Gap** (50-100): Some supply shortage
- **High Gap** (100-200): Significant supply gap
- **Critical Gap** (> 200): Severe supply shortage

### KPI Definitions
- **Avg Gap Score**: Mean gap score across all categories
- **Critical Categories**: Count of categories with Critical/High gaps
- **Critical %**: Percentage of categories with severe gaps
- **Total Supply**: Sum of unique products across all categories
- **Total Demand**: Sum of all order quantities
- **Return Rate**: (Returns / Sales) Ã— 100

---

## Weekly Monitoring Workflow

1. **Run Notebook 8** weekly
2. **Generates**:
   - New snapshot (JSON/CSV) with current gap scores
   - Comparison with previous week
   - List of categories with:
     - Gap increasing (needs attention)
     - Gap improving (positive trend)
     - Supply drops or demand spikes
   - Prioritized action plans (High/Medium/Low)
3. **API Endpoints Update**:
   - `/api/monitoring/snapshot/latest` â†’ New snapshot
   - `/api/monitoring/alerts` â†’ Updated alert list
   - `/api/actions/current-week` â†’ New action plan

---

## Team Contributions

- **Hamza** - Notebooks 1, 5: Data exploration, gap score implementation, territory analysis
- **Ahmad** - Notebook 2: Data cleaning, missing value handling, type conversions
- **Moaz** - Notebooks 3, 4, 6, 7, 8: Supply-demand computation, KPI definition, visualizations, monitoring, action planning

---

## API Endpoint Recommendations

### Core Data Endpoints
```
GET /api/gaps/categories           â†’ Category Gaps sheet (4 categories)
GET /api/gaps/subcategories        â†’ Subcategory Gaps sheet (37 subcategories)
GET /api/gaps/territories          â†’ Territory Gaps sheet
GET /api/gaps/category/{name}      â†’ Single category details
GET /api/gaps/subcategory/{name}   â†’ Single subcategory details
```

### Visualization Endpoints
```
GET /api/viz/supply-demand         â†’ HTML: Supply vs Demand chart
GET /api/viz/severity              â†’ HTML: Gap severity chart
GET /api/viz/heatmap               â†’ HTML: Normalized metrics heatmap
GET /api/viz/rankings              â†’ HTML: Top/bottom rankings
GET /api/viz/distribution          â†’ HTML: Gap distribution pie
```

### Monitoring Endpoints
```
GET /api/monitoring/snapshot/latest        â†’ Latest snapshot JSON
GET /api/monitoring/snapshot/{week}        â†’ Specific week snapshot
GET /api/monitoring/kpis                   â†’ Current KPIs
GET /api/monitoring/alerts                 â†’ Flagged categories
GET /api/monitoring/trends                 â†’ Historical gap trends
```

### Action Planning Endpoints
```
GET /api/actions/current-week              â†’ Latest action plan JSON
GET /api/actions/category/{name}           â†’ Category-specific actions
GET /api/actions/priorities                â†’ Sorted by priority
```

### Insights Endpoints
```
GET /api/insights/interpretation           â†’ Full 2000+ word analysis
GET /api/insights/recommendations          â†’ Extracted recommendations
GET /api/insights/executive-summary        â†’ Brief summary
GET /api/insights/charts                   â†’ Chart-specific insights
```

### Data Export Endpoints
```
GET /api/data/subcategory-summary.csv      â†’ CSV download
GET /api/data/subcategory-summary.json     â†’ JSON download
GET /api/data/comprehensive-report.xlsx    â†’ Full Excel report
```

---

## Module Import Examples

```python
# In your API backend:
from Gap_Analysis.src import (
    load_excel_sheets,           # Load data
    compute_subcategory_supply,  # Calculate supply
    compute_subcategory_demand,  # Calculate demand
    compute_gap_score,           # Calculate gaps
    classify_gap_level,          # Classify severity
    MonitoringSnapshot,          # Weekly tracking
    ActionPlanner,               # Generate actions
    create_supply_demand_chart,  # Create visualizations
    generate_interpretation_and_insights  # Generate insights
)

# Load and process data
datasets = load_excel_sheets('data/processed/Cleaned_data.xlsx')
supply = compute_subcategory_supply(datasets['Sales Data'], products_full)
demand = compute_subcategory_demand(sales_full)
gaps = compute_gap_score(merge_supply_demand(supply, demand))
gaps = classify_gap_level(gaps)

# Generate insights
insights = generate_interpretation_and_insights(gaps)

# Create action plan
planner = ActionPlanner()
actions = planner.generate_category_action_plan(gaps)
```

---

**Total Notebooks**: 8  
**Total Python Modules**: 21  
**Total Output Files**: 30+  
**API-Ready Outputs**: 15+ endpoints
=======
# Renty E-commerce Recommendation System

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![LightFM](https://img.shields.io/badge/LightFM-1.17-green.svg)](https://github.com/lyst/lightfm)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

A comprehensive hybrid recommendation system built with LightFM for the Renty e-commerce platform. This system leverages both collaborative filtering and content-based approaches to deliver personalized product recommendations based on user demographics, purchase behavior, and product features.

## ðŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Dataset](#dataset)
- [Architecture](#architecture)
- [Installation](#installation)
- [Usage](#usage)
- [Model Performance](#model-performance)
- [Project Structure](#project-structure)
- [Technical Details](#technical-details)
- [Future Improvements](#future-improvements)
- [Contributing](#contributing)
- [License](#license)
- [Acknowledgments](#acknowledgments)

## ðŸŽ¯ Overview

The Renty E-commerce Recommendation System is designed to enhance user experience and increase sales by providing intelligent, personalized product recommendations. The system analyzes historical transaction data, user demographics, and product characteristics to predict items that customers are most likely to purchase.

### Key Highlights

- **Hybrid Approach**: Combines collaborative filtering with content-based filtering
- **Advanced Feature Engineering**: RFM-based customer segmentation, temporal features, and TF-IDF text features
- **Robust Performance**: Test AUC of 0.84+ with low overfitting (gap < 0.05)
- **Production Ready**: Includes model persistence and inference pipeline

## âœ¨ Features

### Model Features

- **User Features**
  - Demographics: Gender, Marital Status, Education Level, Occupation, Home Ownership
  - Income Segmentation: 6-level income brackets (VeryLow to Premium)
  - Family Structure: Children categories (NoChildren, OneChild, TwoChildren, ManyChildren)
  - Behavioral Metrics: Total orders, unique products purchased, average order quantity
  - Customer Segments: Bronze, Silver, Gold, Platinum (RFM-inspired)
  - Temporal Features: Season, day of week, weekend indicator

- **Item Features**
  - Product Categories: Extracted from model names
  - Popularity Metrics: 5-level percentile ranking (Niche to Viral)
  - Text Features: TF-IDF extracted from product descriptions (50 features)
  - Customer Reach: Unique customer count per product

### System Capabilities

- âœ… Personalized top-N recommendations
- âœ… Filtering of already-purchased items
- âœ… Real-time prediction for new users (cold-start handling)
- âœ… Comprehensive evaluation metrics (Precision@K, Recall@K, AUC)
- âœ… Hyperparameter optimization with regularization
- âœ… Model serialization for deployment

## ðŸ“Š Dataset

### Data Overview

- **Total Transactions**: 55,666 orders
- **Unique Users**: 17,293 customers
- **Unique Products**: 130 items
- **Date Range**: January 2020 - June 2022
- **Sparsity**: 97.52%

### Data Schema

| Column | Type | Description |
|--------|------|-------------|
| OrderDate | datetime64 | Date of purchase |
| StockDate | datetime64 | Date item was stocked |
| OrderNumber | object | Unique order identifier |
| ProductKey | int64 | Product identifier |
| CustomerKey | int64 | Customer identifier |
| TerritoryKey | int64 | Geographic territory |
| OrderLineItem | int64 | Line item number |
| OrderQuantity | int64 | Quantity ordered |
| ModelName | object | Product model name |
| ProductDescription | object | Product description text |
| MaritalStatus | object | Customer marital status |
| Gender | object | Customer gender |
| AnnualIncome | int64 | Annual income ($) |
| TotalChildren | int64 | Number of children |
| EducationLevel | object | Education level |
| Occupation | object | Customer occupation |
| HomeOwner | object | Home ownership status |

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Data Preprocessing                        â”‚
â”‚  â€¢ Load Excel data                                           â”‚
â”‚  â€¢ Convert datetime columns                                  â”‚
â”‚  â€¢ Remove duplicates                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Advanced Feature Engineering                    â”‚
â”‚  â€¢ Temporal features (year, month, quarter, season)         â”‚
â”‚  â€¢ Income brackets & children categories                    â”‚
â”‚  â€¢ User engagement metrics (RFM-inspired)                   â”‚
â”‚  â€¢ Customer segmentation (Bronze/Silver/Gold/Platinum)      â”‚
â”‚  â€¢ Item popularity percentiles                               â”‚
â”‚  â€¢ MinMax scaling for numerical features                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Text Feature Extraction (TF-IDF)               â”‚
â”‚  â€¢ Extract 50 features from product descriptions           â”‚
â”‚  â€¢ Use unigrams and bigrams                                 â”‚
â”‚  â€¢ Filter by min document frequency                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                LightFM Data Preparation                      â”‚
â”‚  â€¢ Build user-item interaction matrices                     â”‚
â”‚  â€¢ Create user feature matrix (17,293 Ã— 17,330)            â”‚
â”‚  â€¢ Create item feature matrix (130 Ã— 206)                   â”‚
â”‚  â€¢ Temporal train/test split (80/20)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Hyperparameter Tuning & Model Training              â”‚
â”‚  â€¢ Grid search with regularization                          â”‚
â”‚  â€¢ WARP loss function (implicit feedback)                   â”‚
â”‚  â€¢ L2 regularization (item_alpha, user_alpha)              â”‚
â”‚  â€¢ Best params: 50 components, 0.05 learning rate          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Model Evaluation & Deployment                   â”‚
â”‚  â€¢ Precision@K, Recall@K, AUC metrics                       â”‚
â”‚  â€¢ Model persistence (pickle)                                â”‚
â”‚  â€¢ Recommendation generation API                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸš€ Installation

### Prerequisites

- Python 3.8 or higher
- pip package manager
- (Optional) Google Colab account for notebook execution

### Setup Instructions

1. **Clone the repository**

```bash
git clone https://github.com/yourusername/renty-recommendation-system.git
cd renty-recommendation-system
```

2. **Create virtual environment** (recommended)

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**

```bash
pip install -r requirements.txt
```

### Required Packages

```
pandas>=1.3.0
numpy>=1.21.0
matplotlib>=3.4.0
seaborn>=0.11.0
scikit-learn>=1.0.0
scipy>=1.7.0
lightfm>=1.17
```

**Note**: The project uses a specific LightFM fork. Install with:

```bash
pip install git+https://github.com/daviddavo/lightfm
```

## ðŸ’» Usage

### Quick Start

#### 1. Train the Model

```python
# Load and train the complete pipeline
from main import main

filepath = "path/to/GradProject_final_1.xlsx"
model, dataset, user_features, item_features, df, results = main(filepath)
```

#### 2. Generate Recommendations

```python
from recommendation_utils import get_recommendations

# Get recommendations for a specific user
user_id = 14574
recommendations = get_recommendations(
    model=model,
    user_id=user_id,
    dataset=dataset,
    user_features=user_features,
    item_features=item_features,
    df=df,
    n_recommendations=10,
    filter_already_purchased=True
)

print(recommendations)
```

#### 3. Load Pre-trained Model

```python
import pickle

def load_model_artifacts(filepath='renty_lightfm_model_artifacts.pkl'):
    with open(filepath, 'rb') as f:
        artifacts = pickle.load(f)
    return (artifacts['model'], 
            artifacts['dataset'], 
            artifacts['user_features'], 
            artifacts['item_features'])

# Load saved model
model, dataset, user_features, item_features = load_model_artifacts()
```

### Interactive Recommendation Interface

```python
# Get user input and generate recommendations
sample_user_id = int(input("Please enter a User ID: "))

get_recommendations_for_input_user(
    user_id_input=sample_user_id,
    model=loaded_model,
    dataset=loaded_dataset,
    user_features=loaded_user_features,
    item_features=loaded_item_features,
    df=df,
    n_recommendations=10
)
```

### Running the Jupyter Notebook

1. Open the notebook in Google Colab or Jupyter:

```bash
jupyter notebook Ecommerce-Recommendation-System_Renty_Ecommerce_v1.ipynb
```

2. Mount Google Drive (if using Colab):

```python
from google.colab import drive
drive.mount('/content/drive')
```

3. Update the filepath to your dataset location
4. Run all cells sequentially

## ðŸ“ˆ Model Performance

### Final Model Metrics

| Metric | Value | Interpretation |
|--------|-------|----------------|
| **Test AUC** | 0.8409 | Good ranking ability |
| **Precision@5** | 0.1505 | 15% of top-5 recommendations are relevant |
| **Precision@10** | 0.1205 | 12% of top-10 recommendations are relevant |
| **Precision@20** | 0.0868 | 9% of top-20 recommendations are relevant |
| **Recall@5** | 0.2698 | Captures 27% of relevant items in top-5 |
| **Recall@10** | 0.4393 | Captures 44% of relevant items in top-10 |
| **Recall@20** | 0.6402 | Captures 64% of relevant items in top-20 |
| **Overfitting Gap** | 0.0493 | Low overfitting, good generalization |

### Optimal Hyperparameters

```python
{
    'no_components': 50,
    'learning_rate': 0.05,
    'loss': 'warp',
    'item_alpha': 1e-05,  # L2 regularization for items
    'user_alpha': 1e-05,  # L2 regularization for users
    'epochs': 60
}
```

### Performance Comparison

The improved model significantly outperforms the baseline:

- **AUC improvement**: +12% (0.75 â†’ 0.84)
- **Overfitting reduction**: -71% (0.17 â†’ 0.05)
- **Precision@10**: Maintained competitive performance with better generalization


## ðŸ”§ Technical Details

### Feature Engineering Pipeline

#### 1. Temporal Features
- **OrderYear, OrderMonth, OrderQuarter**: Capture temporal trends
- **DayOfWeek, IsWeekend**: Identify purchasing patterns
- **Season**: Spring, Summer, Fall, Winter categorization

#### 2. User Segmentation
```python
# RFM-inspired Customer Value Score
CustomerValueScore = (
    TotalOrders * 0.3 +
    UniqueProducts * 0.3 +
    (TotalQuantity / TotalQuantity.max()) * 100 * 0.4
)

# Segment into tiers
CustomerSegment = pd.qcut(CustomerValueScore, q=4, 
                          labels=['Bronze', 'Silver', 'Gold', 'Platinum'])
```

#### 3. Text Feature Extraction
```python
# TF-IDF Vectorization
tfidf = TfidfVectorizer(
    max_features=50,
    stop_words='english',
    ngram_range=(1, 2),
    min_df=2
)
```

### LightFM Model Configuration

#### Loss Function: WARP (Weighted Approximate-Rank Pairwise)
- Optimized for implicit feedback scenarios
- Focuses on ranking relevant items higher than irrelevant ones
- Particularly effective for top-N recommendations

#### Regularization Strategy
- **L2 Regularization**: Prevents overfitting on sparse data
- **Item Alpha (1e-05)**: Regularizes item feature embeddings
- **User Alpha (1e-05)**: Regularizes user feature embeddings

### Train/Test Split Strategy

**Temporal Split (80/20)**
- Training: First 80% of data chronologically (44,532 samples)
- Testing: Most recent 20% of data (11,134 samples)
- Simulates real-world scenario where model predicts future purchases

### Evaluation Methodology

```python
# Precision@K: Fraction of recommended items that are relevant
Precision@K = (Relevant items in top-K) / K

# Recall@K: Fraction of relevant items that are recommended
Recall@K = (Relevant items in top-K) / (Total relevant items)

# AUC: Area Under ROC Curve
# Measures the model's ability to rank relevant items higher
```

## ðŸ”® Future Improvements

### Short-term Enhancements
- [ ] Implement real-time recommendation API with Flask/FastAPI
- [ ] Add A/B testing framework for model evaluation
- [ ] Create recommendation diversity metrics
- [ ] Develop cold-start strategy for new users/items
- [ ] Add explainability features (why this recommendation?)

### Medium-term Goals
- [ ] Integrate deep learning approaches (Neural Collaborative Filtering)
- [ ] Implement session-based recommendations (RNN/Transformer)
- [ ] Add multi-objective optimization (relevance + diversity + serendipity)
- [ ] Create recommendation confidence scores
- [ ] Develop automated retraining pipeline

### Long-term Vision
- [ ] Build real-time streaming recommendation system
- [ ] Implement contextual bandits for online learning
- [ ] Add multi-modal features (images, reviews, ratings)
- [ ] Create recommendation explanation dashboard
- [ ] Develop cross-domain recommendation capabilities

## ðŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

### Contribution Guidelines

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### Code Style
- Follow PEP 8 style guide for Python code
- Add docstrings to all functions and classes
- Include type hints where appropriate
- Write unit tests for new features

## ðŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ðŸ™ Acknowledgments

- **LightFM Library**: For providing an excellent hybrid recommendation framework
- **Renty E-commerce**: For the dataset and use case
- **Team Members**: 
  - Abdulrahman (Data Analysis & EDA)
  - Yasser Ashraf (Model Development)
  - Moamen Ahmed (Model Evaluation)

## ðŸ“ž Contact

For questions or feedback, please reach out:

- **Email**: yasserashraf3142@gmail.com
- **LinkedIn**: [Yasser Ashraf](https://www.linkedin.com/in/yasserashraf/)

**â­ If you find this project helpful, please consider giving it a star!**

Last Updated: November 2025
>>>>>>> development
