# -*- coding: utf-8 -*-
"""COMPREHENSIVE_MODEL_EVALUATION

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Sqnl4IZbyQn8S-K0r4ltkBzuxfUkAfw8
"""



"""## COMPREHENSIVE MODEL EVALUATION"""

def evaluate_model(model, train_interactions, test_interactions,
                   user_features, item_features, k_values=[5, 10, 20]):
    """Comprehensive model evaluation with comparison metrics"""
    print("\n" + "=" * 80)
    print("STEP 7: COMPREHENSIVE MODEL EVALUATION")
    print("=" * 80)

    results = {}

    print("\n PRECISION & RECALL METRICS:")
    print("-" * 80)
    for k in k_values:
        test_precision = precision_at_k(model, test_interactions,
                                       user_features=user_features,
                                       item_features=item_features, k=k).mean()
        test_recall = recall_at_k(model, test_interactions,
                                 user_features=user_features,
                                 item_features=item_features, k=k).mean()

        results[f'precision@{k}'] = test_precision
        results[f'recall@{k}'] = test_recall

        print(f"  Precision@{k}: {test_precision:.4f} | Recall@{k}: {test_recall:.4f}")

    # AUC Score
    print("\n AUC SCORES:")
    print("-" * 80)
    train_auc = auc_score(model, train_interactions,
                         user_features=user_features,
                         item_features=item_features).mean()
    test_auc = auc_score(model, test_interactions,
                        user_features=user_features,
                        item_features=item_features).mean()

    overfitting_gap = train_auc - test_auc

    results['train_auc'] = train_auc
    results['test_auc'] = test_auc
    results['overfitting_gap'] = overfitting_gap

    print(f"  Train AUC: {train_auc:.4f}")
    print(f"  Test AUC:  {test_auc:.4f}")
    print(f"  Overfitting Gap: {overfitting_gap:.4f}")

    # Interpretation
    print("\n PERFORMANCE INTERPRETATION:")
    print("-" * 80)
    if test_auc >= 0.85:
        print(" Excellent: Model has very strong ranking ability")
    elif test_auc >= 0.75:
        print(" Good: Model performs well at ranking recommendations")
    elif test_auc >= 0.65:
        print(" Fair: Model shows moderate ranking capability")
    else:
        print(" Poor: Model needs improvement")

    if overfitting_gap < 0.1:
        print(" Low overfitting: Model generalizes well to unseen data")
    elif overfitting_gap < 0.15:
        print(" Moderate overfitting: Some generalization loss")
    else:
        print(" High overfitting: Model may not generalize well")

    return results